Mosscap: A local interaction
============================

Local LLM chat using Streamlit with LangChain and Ollama.

Goals:

- Allow user to pick models downloaded via Ollama
- *Remember* chat history during session
- Store conversations for reference in future sessions

